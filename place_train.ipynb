{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from edf.pc_utils import draw_geometry, create_o3d_points\n",
    "from edf.data import PointCloud, SE3, TargetPoseDemo, DemoSequence, DemoSeqDataset, gzip_save\n",
    "from edf.preprocess import Rescale, NormalizeColor, Downsample, PointJitter, ColorJitter\n",
    "from edf.agent import PickAgent, PlaceAgent\n",
    "\n",
    "import numpy as np\n",
    "import yaml\n",
    "import plotly as pl\n",
    "import plotly.express as ple\n",
    "import open3d as o3d\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import Compose\n",
    "\n",
    "torch.set_printoptions(precision= 3, sci_mode=False, linewidth=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_config_dir = \"config/agent_config/place_agent_dev.yaml\"\n",
    "train_config_dir = \"config/train_config/train_place_dev.yaml\"\n",
    "agent_param_dir = \"checkpoint/mug_10_demo/place_dev\"\n",
    "\n",
    "with open(train_config_dir) as file:\n",
    "    config = yaml.load(file, Loader=yaml.FullLoader)\n",
    "device = config['device']\n",
    "unit_len = config['characteristic_length']\n",
    "temperature = config['temperature']\n",
    "max_epochs = config['max_epochs']\n",
    "N_transform_init = config['N_transform_init']\n",
    "mh_iter_init = config['mh_iter_init']\n",
    "langevin_iter_init = config['langevin_iter_init']\n",
    "langevin_begin_epoch = config['langevin_begin_epoch']\n",
    "report_freq = config['report_freq']\n",
    "init_CD_ratio = config['init_CD_ratio']\n",
    "end_CD_ratio = config['end_CD_ratio']\n",
    "CD_end_iter = config['CD_end_iter']\n",
    "lr_se3T = config['lr_se3T']\n",
    "lr_energy_fast = config['lr_energy_fast']\n",
    "lr_energy_slow = config['lr_energy_slow']\n",
    "lr_query_fast = config['lr_query_fast']\n",
    "lr_query_slow = config['lr_query_slow']\n",
    "std_theta_perturb = config['std_theta_degree_perturb'] / 180 * np.pi\n",
    "std_X_perturb = config['std_X_perturb']\n",
    "edf_norm_std = config['edf_norm_std']\n",
    "query_anneal_end_iter = config['query_anneal_end_iter']\n",
    "query_init_temp = config['query_init_temp']\n",
    "query_end_temp = config['query_end_temp']\n",
    "elbo_end_iter = config['elbo_end_iter']\n",
    "langevin_dt = config['langevin_dt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_transforms = Compose([Rescale(rescale_factor=1/unit_len),\n",
    "                          ])\n",
    "trainset = DemoSeqDataset(dataset_dir=\"demo/test_demo\", annotation_file=\"data.yaml\", load_transforms = load_transforms, device=device)\n",
    "train_dataloader = DataLoader(trainset, shuffle=False, collate_fn=lambda x:x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_voxel_size = 1.7\n",
    "grasp_voxel_size = 1.4\n",
    "scene_points_jitter = scene_voxel_size * 0.1\n",
    "grasp_points_jitter = grasp_voxel_size * 0.1\n",
    "scene_color_jitter = 0.015\n",
    "grasp_color_jitter = 0.015\n",
    "\n",
    "scene_proc_fn = Compose([Downsample(voxel_size=1.7, coord_reduction=\"average\"),\n",
    "                         NormalizeColor(color_mean = torch.tensor([0.5, 0.5, 0.5]), color_std = torch.tensor([0.5, 0.5, 0.5])),\n",
    "                         PointJitter(jitter_std=scene_points_jitter),\n",
    "                         ColorJitter(jitter_std=scene_color_jitter)\n",
    "                         ])\n",
    "grasp_proc_fn = Compose([Downsample(voxel_size=1.4, coord_reduction=\"average\"),\n",
    "                         NormalizeColor(color_mean = torch.tensor([0.5, 0.5, 0.5]), color_std = torch.tensor([0.5, 0.5, 0.5])),\n",
    "                         PointJitter(jitter_std=grasp_points_jitter),\n",
    "                         ColorJitter(jitter_std=grasp_color_jitter)\n",
    "                         ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "place_agent = PlaceAgent(config_dir=agent_config_dir, device=device, lr_se3T=lr_se3T, lr_energy_fast = lr_energy_fast, \n",
    "                            lr_energy_slow = lr_energy_slow, lr_query_fast = lr_query_fast, lr_query_slow = lr_query_slow, \n",
    "                            std_theta_perturb=std_theta_perturb, std_X_perturb=std_X_perturb, langevin_dt=langevin_dt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_checkpoint = True\n",
    "visualize = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iter = len(trainset) * max_epochs\n",
    "iter = 0\n",
    "for epoch in range(1, max_epochs+1):\n",
    "    for train_batch in train_dataloader:\n",
    "        iter += 1\n",
    "        assert len(train_batch) == 1, \"Batch training is not supported yet.\"\n",
    "\n",
    "        data = train_batch[0]\n",
    "        demo_seq: DemoSequence = data.to(device)\n",
    "        place_demo: TargetPoseDemo = demo_seq[1]\n",
    "        scene_raw: PointCloud = place_demo.scene_pc\n",
    "        grasp_raw: PointCloud = place_demo.grasp_pc\n",
    "        target_poses: SE3 = place_demo.target_poses\n",
    "        scene_proc = scene_proc_fn(scene_raw)\n",
    "        grasp_proc = grasp_proc_fn(grasp_raw)\n",
    "        \n",
    "\n",
    "        ################################################# Train #########################################################\n",
    "        N_transforms = N_transform_init\n",
    "        mh_iter = mh_iter_init\n",
    "        if epoch >= langevin_begin_epoch:\n",
    "            langevin_iter = int( langevin_iter_init * (1+ iter / max_iter) )\n",
    "        else:\n",
    "            langevin_iter = 0\n",
    "        \n",
    "        if iter % report_freq == 0 or iter == 1:\n",
    "            pbar = True\n",
    "            verbose = True\n",
    "            if visualize:\n",
    "                raise NotImplementedError\n",
    "            else:\n",
    "                pass\n",
    "        else:\n",
    "            pbar = False\n",
    "            verbose = False\n",
    "            visual_info = None\n",
    "\n",
    "        if iter > CD_end_iter:\n",
    "            CD_ratio = end_CD_ratio\n",
    "        else:\n",
    "            p_CD = 1 - (iter-1)/CD_end_iter\n",
    "            CD_ratio = p_CD*init_CD_ratio + (1-p_CD)*end_CD_ratio\n",
    "        if iter > query_anneal_end_iter:\n",
    "            query_temperature = query_end_temp\n",
    "        else:\n",
    "            p_qt = 1 - (iter-1)/query_anneal_end_iter\n",
    "            query_temperature = p_qt*query_init_temp + (1-p_qt)*query_end_temp\n",
    "\n",
    "        if iter > elbo_end_iter:\n",
    "            use_surrogate = False\n",
    "        else:\n",
    "            use_surrogate = True\n",
    "\n",
    "        if iter == int(max_iter * 0.9):\n",
    "            print(\"Lower lr rate\")\n",
    "            place_agent.rescale_lr(factor=0.2)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"=========Iter {iter}=========\", flush=True)\n",
    "        train_logs = place_agent.train_once(scene=scene_proc, target_T = target_poses, N_transforms = N_transforms,\n",
    "                                            mh_iter = mh_iter, langevin_iter = langevin_iter, temperature = temperature, \n",
    "                                            pbar = pbar, verbose = verbose, grasp=grasp_proc, \n",
    "                                            CD_ratio = CD_ratio, edf_norm_std=edf_norm_std, query_temperature=query_temperature, surrogate_query=use_surrogate)\n",
    "        \n",
    "        train_logs['scene_raw'] = scene_raw.to('cpu')\n",
    "        train_logs['grasp_raw'] = grasp_raw.to('cpu')\n",
    "        train_logs['scene_proc'] = scene_proc.to('cpu')\n",
    "        train_logs['grasp_proc'] = grasp_proc.to('cpu')\n",
    "\n",
    "        if iter % report_freq == 0 or iter == 1:\n",
    "            if save_checkpoint:\n",
    "                filename = f'model_iter_{iter}.pt'\n",
    "                place_agent.save(agent_param_dir, filename)\n",
    "\n",
    "                log_filename = f'trainlog_iter_{iter}.gzip'\n",
    "                gzip_save(train_logs, dir=agent_param_dir, filename=log_filename)\n",
    "                \n",
    "        if verbose:\n",
    "            print(\"===============================\", flush=True)\n",
    "        \n",
    "        \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "af6666271aa88010cf2cfaabf400b3e4725e891d1262c16234a99fd43f726498"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
